{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2 AS-IS: timeout debug ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled_data_export_intermediate_10: {'participant_persona': {'participant_1': {'name': 'Emily', 'age': 28, 'gender': 'Female', 'personality': 'Thoughtful and introspective, enjoys deep conversations and values her faith.', 'background': \"i enjoy listening to classical music. i'm a christian. my favorite color is red. i can drive a tractor. my sister is a pole dancer.\"}, 'participant_2': {'name': 'George', 'age': 35, 'gender': 'Male', 'personality': 'Pragmatic and straightforward, has a love for nature and farming.', 'background': \"i am a bee farmer. i have zero family that i'm close to. my name is george. my favorite food is papaya.\"}}, 'messages': [{'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 20, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 10, 'Boredom': 5, 'Neutral': 40}, 'text': 'Hello! How is your going?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 25, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 5, 'Neutral': 30}, 'text': 'Do you like to chat with me?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 25, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 5, 'Neutral': 30}, 'text': 'Good morning! How are you?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 5, 'Neutral': 35}, 'text': \"I'm good. Just listening to some classical music. You?\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 10, 'Neutral': 35}, 'text': \"Don't know yet\"}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 5, 'Neutral': 50}, 'text': 'I will mention that to my the kind people in the lab,.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 10, 'Neutral': 45}, 'text': 'Just woke up'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 10, 'Love': 15, 'Boredom': 5, 'Neutral': 35}, 'text': 'Oh wow, I am sorry to hear that.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 10, 'Neutral': 35}, 'text': 'Why are you sprry? It is a morning here...'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 10, 'Love': 20, 'Boredom': 5, 'Neutral': 30}, 'text': \"I'm not going to be late.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 10, 'Neutral': 45}, 'text': 'Where are you goin?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 10, 'Neutral': 45}, 'text': 'To the top of the street.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 5, 'Sadness': 5, 'Surprise': 5, 'Love': 10, 'Boredom': 10, 'Neutral': 50}, 'text': \"what's there?\"}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 10, 'Love': 20, 'Boredom': 10, 'Neutral': 35}, 'text': 'Hi, I am listening to some classical music.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 20, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 10, 'Neutral': 30}, 'text': 'you told me that already.... nevermind'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 35}, 'text': \"I didn't ask.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 35}, 'text': 'what is your name?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 40}, 'text': \"I'm not saying that.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 10, 'Sadness': 0, 'Surprise': 0, 'Love': 20, 'Boredom': 10, 'Neutral': 60}, 'text': 'who are you?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 20, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 5, 'Neutral': 35}, 'text': \"I'm the one who's the one who's here.\"}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 30}, 'text': 'We live in simulation, right?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 10, 'Love': 20, 'Boredom': 10, 'Neutral': 35}, 'text': 'no, I live a real life, you are the simulation'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 30}, 'text': 'I am a christian, christian, and I love classical music.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 40}, 'text': 'Who is the head of the church?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 35}, 'text': 'It depends on the historical context, because it changes from time to time.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 15, 'Sadness': 0, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 40}, 'text': 'what about now?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 30}, 'text': \"I don't know.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 35}, 'text': 'ok'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 30}, 'text': 'Are you kidding?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 30, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 15, 'Boredom': 10, 'Neutral': 20}, 'text': 'stupid answer...'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 25, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 5, 'Neutral': 25}, 'text': \"Why don't they just legalize abortions?\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 30}, 'text': 'we should'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 30}, 'text': 'We have to be the same'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 25, 'Boredom': 10, 'Neutral': 30}, 'text': 'I just remembered. oh wow! I am a christian. I am a christian.'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 25, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 20}, 'text': 'We live in simulation, right?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 15, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 25, 'Boredom': 10, 'Neutral': 20}, 'text': 'Hey, listen. oh wow! I am a christian. I love to drive my truck.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 10, 'Sadness': 0, 'Surprise': 0, 'Love': 20, 'Boredom': 10, 'Neutral': 60}, 'text': 'I am a bee farmer'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 15, 'Sadness': 0, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 50}, 'text': 'You are a bee farmer? How do you like your work?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 10, 'Neutral': 30}, 'text': 'it is tiresome but fruitful'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 20, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 5, 'Neutral': 30}, 'text': 'I drive a truck. I drive a truck.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 0, 'Joy': 10, 'Sadness': 0, 'Surprise': 0, 'Love': 20, 'Boredom': 10, 'Neutral': 55}, 'text': 'Do you drive christian truck?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 15, 'Fear': 0, 'Joy': 15, 'Sadness': 0, 'Surprise': 5, 'Love': 25, 'Boredom': 10, 'Neutral': 30}, 'text': 'No, I drive a truck. I drive a truck.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 0, 'Joy': 10, 'Sadness': 0, 'Surprise': 5, 'Love': 25, 'Boredom': 10, 'Neutral': 40}, 'text': 'Are you a driver?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 10, 'Sadness': 0, 'Surprise': 0, 'Love': 20, 'Boredom': 10, 'Neutral': 60}, 'text': \"I'm a driver.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 15, 'Fear': 5, 'Joy': 15, 'Sadness': 0, 'Surprise': 5, 'Love': 25, 'Boredom': 10, 'Neutral': 25}, 'text': 'cool'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 25, 'Fear': 5, 'Joy': 10, 'Sadness': 5, 'Surprise': 5, 'Love': 20, 'Boredom': 5, 'Neutral': 25}, 'text': \"This is the biggest lie I've ever heard.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 0, 'Joy': 15, 'Sadness': 0, 'Surprise': 0, 'Love': 20, 'Boredom': 10, 'Neutral': 45}, 'text': 'bye'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 0, 'Surprise': 0, 'Love': 20, 'Boredom': 10, 'Neutral': 40}, 'text': 'Bye bye!'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 5, 'Joy': 15, 'Sadness': 0, 'Surprise': 0, 'Love': 20, 'Boredom': 10, 'Neutral': 45}, 'text': 'I just remembered. hi how are you today'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 0, 'Surprise': 0, 'Love': 25, 'Boredom': 10, 'Neutral': 35}, 'text': 'What do you feel about my person? hi how are you today'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 10, 'Fear': 5, 'Joy': 15, 'Sadness': 5, 'Surprise': 5, 'Love': 25, 'Boredom': 10, 'Neutral': 25}, 'text': 'We live in simulation, right?'}}]}\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# 24. 09. 24.\n",
    "# 각 폴더 별로 5개씩 테스트 완료\n",
    "# 잘 변환되어 들어가는 것을 확인.\n",
    "# sh 스크립트로도 잘 돌아가는 것을 확인.\n",
    "# 최종 검수 후 전체 파일 돌리면 됨.\n",
    "\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List\n",
    "import glob\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = openai\n",
    "\n",
    "def label_emotion(data: Dict) -> Dict:\n",
    "    for message in data['messages']:\n",
    "        content = message.get('content', {})\n",
    "        if not content.get('emotion_scores') and 'text' in content:\n",
    "            text = content['text']\n",
    "            prompt = f\"\"\"Analyze the following text and provide emotion_scores field for the following categories: Anger, Fear, Joy, Sadness, Surprise, Love, Boredom, Neutral. The output should be in JSON format with the emotion categories as keys and their respective scores as values, totaling exactly 100. \n",
    "\n",
    "            # Guidelines:\n",
    "            1. Consider the Participant Information and Conversation Log when interpreting the emotional content of the text.\n",
    "            2. Maintain a Neutral score of around 60, if there are no clear emotional cues.\n",
    "            3. Assign a very high score (over 60) to that emotion category when there is clear evidence of a specific emotion in the text.\n",
    "\n",
    "            # Participant Information: \n",
    "            {data[\"participant_persona\"]},\n",
    "\n",
    "            # Conversation Log:\n",
    "            {data[\"messages\"]}\n",
    "        \n",
    "            # Expected output example:\n",
    "            \"emotion_scores\": {{\n",
    "                \"Anger\": ,\n",
    "                \"Fear\": ,\n",
    "                \"Joy\": ,\n",
    "                \"Sadness\": \n",
    "                \"Surprise\": ,\n",
    "                \"Love\": ,\n",
    "                \"Boredom\": ,\n",
    "                \"Neutral\": \n",
    "            }},\n",
    "            \"text\": \"{text}\"\n",
    "            \n",
    "            Ensure that your scoring reflects the intensity and clarity of the emotional expression in the text.\"\"\"\n",
    "\n",
    "            response = client.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an AI assistant that helps to build conversation data set.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.8,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "\n",
    "            response_content = response.choices[0].message.content\n",
    "\n",
    "            try:\n",
    "                filled_data = json.loads(response_content)  \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError: {e}\")\n",
    "                continue\n",
    "\n",
    "            if content.get('text') == text:\n",
    "                content['emotion_scores'] = filled_data.get('emotion_scores', {})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "foleder_name = \"intermediate\"\n",
    "\n",
    "json_file = \"/home/user1/conversation-data/dataset-01-convai/data/03_filled_data/intermediate/filled_data_intermediate_4.json\"\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "filled_data = label_emotion(data)\n",
    "print(f\"filled_data_export_{foleder_name}_{i + 1}:\", filled_data)\n",
    "print(\"=====================================\")\n",
    "\n",
    "output_dir = f'/home/user1/conversation-data/dataset-01-convai/data/04_emotion_labeled_data/{foleder_name}/test'\n",
    "output_file = os.path.join(output_dir, f'output-message.json')\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(filled_data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled_data_export_intermediate_1: {'participant_persona': {'participant_1': {'name': 'Ethan', 'age': 27, 'gender': 'Male', 'personality': 'Curious and adventurous, Ethan loves exploring new things and has a strong appreciation for arts and sports.', 'background': 'i try various coffees as a hobby. i enjoy poetry. i am a huge star wars fan. i played football for a division a college.'}, 'participant_2': {'name': 'Sofia', 'age': 25, 'gender': 'Female', 'personality': 'Friendly and outgoing, Sofia enjoys meeting new people and sharing her love for music and stories.', 'background': \"my favourite music is country music. i drive a nissan pathfinder. i met taylor swift. i've short brown hair.\"}}, 'messages': [{'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 10, 'Neutral': 90}, 'text': 'Are u there?'}}]}\n",
      "=====================================\n",
      "filled_data_export_intermediate_2: {'participant_persona': {'participant_1': {'name': 'Emily', 'age': 21, 'gender': 'female', 'personality': 'Outgoing and friendly, enjoys socializing with others.', 'background': \"i've blonde hair and blue eyes. i do not like chicken. i work at a bar at night to pay for college. i recently got an apartment with my best friend.\"}, 'participant_2': {'name': 'Marco', 'age': 24, 'gender': 'male', 'personality': 'Creative and passionate about music and languages.', 'background': \"one of the languages that i'm currently studying is spanish. i am a musician. my favorite spanish word is trabajo. i also study languages. my next language to study is french.\"}}, 'messages': [{'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 60, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 0, 'Neutral': 40}, 'text': 'Buongiorno! Such a nice day! How are you?.\\nShort bio: do not like chicken'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 10, 'Neutral': 90}, 'text': 'Hello! Are you Italian?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 10, 'Sadness': 0, 'Surprise': 10, 'Love': 0, 'Boredom': 20, 'Neutral': 60}, 'text': 'no . i do not have any degrees . i larp . do you ?'}}]}\n",
      "=====================================\n",
      "filled_data_export_intermediate_3: {'participant_persona': {'participant_1': {'name': 'Emily', 'age': 27, 'gender': 'Female', 'personality': 'Sensitive and introverted, Emily tends to avoid situations that make her uncomfortable.', 'background': 'i faint at the sight of blood. my dream in life is to work from home. i have an internet addiction and spend a lot of time playing roleplaying games. i went to school to be a veterinarian but hated it.'}, 'participant_2': {'name': 'Jake', 'age': 30, 'gender': 'Male', 'personality': 'Energetic and outgoing, Jake enjoys staying fit and socializing at the gym.', 'background': \"i like doing the treadmill and rowing machine. i go to the gym regularly. i have short hair. eating is something i do when i'm bored.\"}}, 'messages': [{'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 10, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 0, 'Neutral': 90}, 'text': 'Hi!'}}]}\n",
      "=====================================\n",
      "filled_data_export_intermediate_4: {'participant_persona': {'participant_1': {'name': 'Alex', 'age': 28, 'gender': 'Male', 'personality': 'Creative and passionate about music.', 'background': 'my pets name is charlie. i produce music for artists. my favourite food is pizza. i drive a 2015 honda civic.'}, 'participant_2': {'name': 'Emily', 'age': 8, 'gender': 'Female', 'personality': 'Energetic and cheerful, loves to play and sing.', 'background': \"i love to go to disney world every year. mickey mouse is my favorite character. i play with my friends on the playground. i love to sing songs from the movie frozen. i'm in the third grade.\"}}, 'messages': [{'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 60, 'Sadness': 0, 'Surprise': 10, 'Love': 0, 'Boredom': 0, 'Neutral': 30}, 'text': 'hi!!'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 50, 'Sadness': 0, 'Surprise': 10, 'Love': 0, 'Boredom': 0, 'Neutral': 40}, 'text': 'how  are u'}}]}\n",
      "=====================================\n",
      "filled_data_export_intermediate_5: {'participant_persona': {'participant_1': {'name': 'Eli Roth', 'age': 29, 'gender': 'Male', 'personality': 'Adventurous and resilient, Eli has a thrill-seeking nature evidenced by his career as a stunt double. He enjoys intellectual pursuits and values healthy living.', 'background': 'i never broke a bone in my body ever in my life. i only eat kosher. i was raised in a single parent household. i am a stunt double as my second job. i read twenty books a year.'}, 'participant_2': {'name': 'Maya Collins', 'age': 34, 'gender': 'Female', 'personality': 'Inspired and determined, Maya embodies positivity and strength, particularly as a cancer survivor. She motivates others to lead healthy lifestyles.', 'background': \"i got a new job just yesterday to be a life coach. i love running and preparing for marathons. i am a clean eater. i'm a cancer survivor. my parents were both very athletic.\"}}, 'messages': [{'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 10, 'Neutral': 85}, 'text': 'And so what?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 10, 'Neutral': 85}, 'text': 'Ok'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 5, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 15, 'Neutral': 80}, 'text': 'Ok'}}]}\n",
      "=====================================\n",
      "filled_data_export_intermediate_6: {'participant_persona': {'participant_1': {'name': 'Emma', 'age': 24, 'gender': 'Female', 'personality': 'Ambitious and determined, Emma is driven by her dreams of becoming a lawyer. She is adventurous and enjoys the idea of city life while cherishing her rural upbringing.', 'background': 'i was raised on a horse farm. my family has raised horses for generations. i dream of moving to the city. i want to be a lawyer.'}, 'participant_2': {'name': 'James', 'age': 42, 'gender': 'Male', 'personality': \"Caring and supportive, James takes pride in his daughter's achievements and balances his professional life as a doctor with family time. He has a whimsical side, enjoying light-hearted movies.\", 'background': 'my daughter is a child prodigy. i enjoy going to the park. i am a doctor. i am now looking for a new job. my favorite movie is friday.'}}, 'messages': [{'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 0, 'Neutral': 100}, 'text': 'Hu'}}, {'role': 'participant_1', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0, 'Love': 0, 'Boredom': 10, 'Neutral': 90}, 'text': 'Hi'}}]}\n",
      "=====================================\n",
      "filled_data_export_intermediate_7: {'participant_persona': {'participant_1': {'name': 'Ethan', 'age': 12, 'gender': 'Male', 'personality': 'Curious and imaginative, he often dreams of superpowers and adventures.', 'background': \"i had to have a transplant. i'm a boy. i was born with my heart outside my body. i can move objects with my mind.\"}, 'participant_2': {'name': 'Lila', 'age': 24, 'gender': 'Female', 'personality': 'Adventurous and free-spirited, she loves the thrill of riding and the rush of life.', 'background': 'i wear a motorbike helmet to protect my head. my main transportation is my motorbike. i have light skin with big brown eyes. i waitress during the day to supplement my income. its red with blue stripe so it shiny when i race.'}}, 'messages': [{'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 20, 'Sadness': 30, 'Surprise': 0, 'Love': 40, 'Boredom': 0, 'Neutral': 10}, 'text': 'Yo! Alright mate?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {'Anger': 0, 'Fear': 0, 'Joy': 10, 'Sadness': 30, 'Surprise': 0, 'Love': 50, 'Boredom': 0, 'Neutral': 10}, 'text': 'I miss you ❤'}}]}\n",
      "=====================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    112\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m--> 114\u001b[0m filled_data \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilled_data_export_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfoleder_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, filled_data)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=====================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 49\u001b[0m, in \u001b[0;36mlabel_emotion\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     20\u001b[0m text \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mAnalyze the following text and provide emotion_scores field for the following categories: Anger, Fear, Joy, Sadness, Surprise, Love, Boredom, Neutral. The output should be in JSON format with the emotion categories as keys and their respective scores as values, totaling exactly 100. \u001b[39m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m# Guidelines:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124mEnsure that your scoring reflects the intensity and clarity of the emotional expression in the text.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an AI assistant that helps to build conversation data set.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m response_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List\n",
    "import glob\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = openai\n",
    "\n",
    "def label_emotion(data: Dict) -> Dict:\n",
    "    for message in data['messages']:\n",
    "        content = message.get('content', {})\n",
    "        if not content.get('emotion_scores') and 'text' in content:\n",
    "            text = content['text']\n",
    "            prompt = f\"\"\"Analyze the following text and provide emotion_scores field for the following categories: Anger, Fear, Joy, Sadness, Surprise, Love, Boredom, Neutral. The output should be in JSON format with the emotion categories as keys and their respective scores as values, totaling exactly 100. \n",
    "\n",
    "            # Guidelines:\n",
    "            1. Consider the Participant Information and Conversation Log when interpreting the emotional content of the text.\n",
    "            2. Subtle emotional cues should be reflected in the corresponding emotion scores, but don't overinterpret.\n",
    "            3. Assign a very high score to that emotion category when there is clear and strong evidence of a specific emotion in the text.\n",
    "\n",
    "            # Participant Information: \n",
    "            {data[\"participant_persona\"]},\n",
    "        \n",
    "            # Expected output example:\n",
    "            \"emotion_scores\": {{\n",
    "                \"Anger\": ,\n",
    "                \"Fear\": ,\n",
    "                \"Joy\": ,\n",
    "                \"Sadness\": \n",
    "                \"Surprise\": ,\n",
    "                \"Love\": ,\n",
    "                \"Boredom\": ,\n",
    "                \"Neutral\": \n",
    "            }},\n",
    "            \"text\": \"{text}\"\n",
    "\n",
    "            # Conversation Log:\n",
    "            {data[\"messages\"]}\n",
    "            \n",
    "            Ensure that your scoring reflects the intensity and clarity of the emotional expression in the text.\"\"\"\n",
    "\n",
    "            response = client.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an AI assistant that helps to build conversation data set.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.8,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "\n",
    "            response_content = response.choices[0].message.content\n",
    "\n",
    "            try:\n",
    "                filled_data = json.loads(response_content)  \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError: {e}\")\n",
    "                continue\n",
    "\n",
    "            if content.get('text') == text:\n",
    "                content['emotion_scores'] = filled_data.get('emotion_scores', {})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# # 한 개 파일 비교\n",
    "# # /home/user1/conversation-data/dataset-01-convai/data/03_filled_data/intermediate/filled_data_intermediate_4.json\n",
    "# # conversation 단위: 2m 1.9s = 대략 2분 소요 \n",
    "# # message 단위: 56.3s = 대략 1분 소요 \n",
    "\n",
    "# foleder_name = \"intermediate\"\n",
    "\n",
    "# json_file = \"/home/user1/conversation-data/dataset-01-convai/data/03_filled_data/intermediate/filled_data_intermediate_4.json\"\n",
    "# with open(json_file, 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# filled_data = label_emotion(data)\n",
    "# print(f\"filled_data_export_{foleder_name}_{i + 1}:\", filled_data)\n",
    "# print(\"=====================================\")\n",
    "\n",
    "# output_dir = f'/home/user1/conversation-data/dataset-01-convai/data/04_emotion_labeled_data/{foleder_name}'\n",
    "# output_file = os.path.join(output_dir, f'emotion_labeled_data_v2_{foleder_name}_4.json')\n",
    "\n",
    "# with open(output_file, 'w', encoding='utf-8') as file:\n",
    "#     json.dump(filled_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 100개 파일 비교\n",
    "# 시간\n",
    "# conversation 단위: \n",
    "# v2 message 단위: 2m 0.2s = 대략 2분 소요\n",
    "# 가격\n",
    "# conversation 단위: \n",
    "# message 단위: \n",
    "\n",
    "foleder_name = \"intermediate\"\n",
    "\n",
    "json_files = sorted(glob.glob(f'/home/user1/conversation-data/dataset-01-convai/data/03_filled_data/{foleder_name}/*.json'))\n",
    "\n",
    "for i, json_file in enumerate(json_files[:50]):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    filled_data = label_emotion(data)\n",
    "    print(f\"filled_data_export_{foleder_name}_{i + 1}:\", filled_data)\n",
    "    print(\"=====================================\")\n",
    "\n",
    "    output_dir = f'/home/user1/conversation-data/dataset-01-convai/data/04_emotion_labeled_data/{foleder_name}/test'\n",
    "    output_file = os.path.join(output_dir, f'emotion_labeled_data_v2_cost-test_{foleder_name}_{i + 1}.json')\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(filled_data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v3 test\n",
    "- conversation 단위로 request 보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "prompt\n",
      "AAnalyze the entire Conversation for each message and provide the emotion_scores field for the following categories: Anger, Fear, Joy, Sadness, Surprise, Love, Boredom, Neutral. The output should be in JSON format with the emotion categories as keys and their respective scores as values, totaling exactly 100. Ensure that the original format of the conversation is preserved. Although considering the context of the whole conversation, analyze each text. \n",
      "\n",
      "    # Guidelines:\n",
      "    1. Consider the Participant Information and Conversation Log when interpreting the emotional content of the text.\n",
      "    2. Subtle emotional cues should be reflected in the corresponding emotion scores, but don't overinterpret.\n",
      "    3. Assign a very high score to that emotion category when there is clear and strong evidence of a specific emotion in the text.\n",
      "\n",
      "    # Participant Information: \n",
      "    {'participant_1': {'name': 'Emily', 'age': 28, 'gender': 'Female', 'personality': 'Thoughtful and introspective, enjoys deep conversations and values her faith.', 'background': \"i enjoy listening to classical music. i'm a christian. my favorite color is red. i can drive a tractor. my sister is a pole dancer.\"}, 'participant_2': {'name': 'George', 'age': 35, 'gender': 'Male', 'personality': 'Pragmatic and straightforward, has a love for nature and farming.', 'background': \"i am a bee farmer. i have zero family that i'm close to. my name is george. my favorite food is papaya.\"}},\n",
      "\n",
      "    # Expected output example:\n",
      "    \"emotion_scores\": {\n",
      "        \"Anger\": ,\n",
      "        \"Fear\": ,\n",
      "        \"Joy\": ,\n",
      "        \"Sadness\": \n",
      "        \"Surprise\": ,\n",
      "        \"Love\": ,\n",
      "        \"Boredom\": ,\n",
      "        \"Neutral\": \n",
      "        },\n",
      "        \"text\": \"each message\",\n",
      "    ...\n",
      "\n",
      "    # Conversation:\n",
      "    [{'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'Hello! How is your going?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'Do you like to chat with me?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'Good morning! How are you?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"I'm good. Just listening to some classical music. You?\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': \"Don't know yet\"}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'I will mention that to my the kind people in the lab,.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'Just woke up'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'Oh wow, I am sorry to hear that.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'Why are you sprry? It is a morning here...'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"I'm not going to be late.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'Where are you goin?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'To the top of the street.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': \"what's there?\"}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'Hi, I am listening to some classical music.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'you told me that already.... nevermind'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"I didn't ask.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'what is your name?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"I'm not saying that.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'who are you?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"I'm the one who's the one who's here.\"}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'We live in simulation, right?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'no, I live a real life, you are the simulation'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'I am a christian, christian, and I love classical music.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'Who is the head of the church?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'It depends on the historical context, because it changes from time to time.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'what about now?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"I don't know.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'ok'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'Are you kidding?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'stupid answer...'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"Why don't they just legalize abortions?\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'we should'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'We have to be the same'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'I just remembered. oh wow! I am a christian. I am a christian.'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'We live in simulation, right?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'Hey, listen. oh wow! I am a christian. I love to drive my truck.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'I am a bee farmer'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'You are a bee farmer? How do you like your work?'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'it is tiresome but fruitful'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'I drive a truck. I drive a truck.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'Do you drive christian truck?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'No, I drive a truck. I drive a truck.'}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'Are you a driver?'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"I'm a driver.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'cool'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': \"This is the biggest lie I've ever heard.\"}}, {'role': 'participant_1', 'content': {'emotion_scores': {}, 'text': 'bye'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'Bye bye!'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'I just remembered. hi how are you today'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'What do you feel about my person? hi how are you today'}}, {'role': 'participant_2', 'content': {'emotion_scores': {}, 'text': 'We live in simulation, right?'}}]\n",
      "    \n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 115\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    113\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m--> 115\u001b[0m filled_data \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilled_data_export_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfoleder_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, filled_data)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=====================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[57], line 72\u001b[0m, in \u001b[0;36mlabel_emotion\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     61\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     62\u001b[0m             model\u001b[38;5;241m=\u001b[39mMODEL,\n\u001b[1;32m     63\u001b[0m             messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m             response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     69\u001b[0m         )\n\u001b[1;32m     71\u001b[0m response_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 72\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mencoding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# Ensure response_content is a string before loading as JSON\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     response_content_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(response_content)\n",
      "File \u001b[0;32m~/conversation-data/.venv/lib/python3.10/site-packages/tiktoken/core.py:116\u001b[0m, in \u001b[0;36mEncoding.encode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(disallowed_special, \u001b[38;5;28mfrozenset\u001b[39m):\n\u001b[1;32m    115\u001b[0m         disallowed_special \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(disallowed_special)\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;241m:=\u001b[39m \u001b[43m_special_token_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisallowed_special\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    117\u001b[0m         raise_disallowed_special_token(match\u001b[38;5;241m.\u001b[39mgroup())\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# https://github.com/PyO3/pyo3/pull/3632\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = openai\n",
    "\n",
    "def label_emotion(data: Dict) -> Dict:\n",
    "    messages = data['messages']\n",
    "    \n",
    "    prompt = f\"\"\"Analyze the entire Conversation for each message and provide the emotion_scores field for the following categories: Anger, Fear, Joy, Sadness, Surprise, Love, Boredom, Neutral. The output should be in JSON format with the emotion categories as keys and their respective scores as values, totaling exactly 100. Ensure that the original format of the conversation is preserved. Although considering the context of the whole conversation, analyze each text. \n",
    "\n",
    "    # Guidelines:\n",
    "    1. Consider the Participant Information and Conversation Log when interpreting the emotional content of the text.\n",
    "    2. Subtle emotional cues should be reflected in the corresponding emotion scores, but don't overinterpret.\n",
    "    3. Assign a very high score to that emotion category when there is clear and strong evidence of a specific emotion in the text.\n",
    "\n",
    "    # Participant Information: \n",
    "    {data[\"participant_persona\"]},\n",
    "\n",
    "    # Expected output example:\n",
    "    \"emotion_scores\": {{\n",
    "        \"Anger\": ,\n",
    "        \"Fear\": ,\n",
    "        \"Joy\": ,\n",
    "        \"Sadness\": \n",
    "        \"Surprise\": ,\n",
    "        \"Love\": ,\n",
    "        \"Boredom\": ,\n",
    "        \"Neutral\": \n",
    "        }},\n",
    "        \"text\": \"each message\",\n",
    "    ...\n",
    "\n",
    "    # Conversation:\n",
    "    {messages}\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"prompt\")\n",
    "    print(prompt)\n",
    "    input_tokens = encoding.encode(prompt)\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.ChatCompletion.create(\n",
    "                        model=MODEL,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You are an AI assistant that helps to build conversation data set.\"},\n",
    "                            {\"role\": \"user\", \"content\": prompt}\n",
    "                        ],\n",
    "                        temperature=0.8,\n",
    "                        response_format={\"type\": \"json_object\"}\n",
    "                    )\n",
    "\n",
    "            response_content = response.choices[0].message['content']\n",
    "            output_tokens = encoding.encode(response)\n",
    "\n",
    "            try:\n",
    "                # Ensure response_content is a string before loading as JSON\n",
    "                response_content_str = str(response_content)\n",
    "                filled_data = json.loads(response_content_str)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError: {e}\")\n",
    "                continue\n",
    "\n",
    "            print(\"-------------------------------\")\n",
    "            print(\"filled_data\")\n",
    "            print(filled_data)\n",
    "            print(\"-------------------------------\")\n",
    "\n",
    "            # for message in messages:\n",
    "            #     content = message.get('content', {})\n",
    "            #     text = content['text']\n",
    "            #     if content.get('text') == text:\n",
    "            #         content['emotion_scores'] = filled_data.get('emotion_scores', {})\n",
    "\n",
    "        except openai.error.Timeout as e:\n",
    "            print(f\"Attempt {attempt + 1} of {retries} failed with timeout. Retrying...\")\n",
    "            time.sleep(3)  # Wait for 3 seconds before retrying\n",
    "    else:\n",
    "        print(f\"Failed to process messages.\")\n",
    "\n",
    "    \n",
    "    # Calculate total tokens\n",
    "    total_tokens = len(input_tokens) + len(output_tokens)\n",
    "\n",
    "    print(f\"Input Tokens: {len(input_tokens)}\")\n",
    "    print(f\"Output Tokens: {len(output_tokens)}\")\n",
    "    print(f\"Total Tokens: {total_tokens}\")\n",
    "\n",
    "    return data  # Return the data after processing all messages\n",
    "\n",
    "foleder_name = \"intermediate\"\n",
    "\n",
    "json_file = \"/home/user1/conversation-data/dataset-01-convai/data/03_filled_data/intermediate/filled_data_intermediate_4.json\"\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "filled_data = label_emotion(data)\n",
    "print(f\"filled_data_export_{foleder_name}_{i + 1}:\", filled_data)\n",
    "print(\"=====================================\")\n",
    "\n",
    "output_dir = f'/home/user1/conversation-data/dataset-01-convai/data/04_emotion_labeled_data/{foleder_name}/test'\n",
    "output_file = os.path.join(output_dir, f'emotion_labeled_data_v2_{foleder_name}_4.json')\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(filled_data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five = \"\"\"\n",
    "   \"messages\": [\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Hello! How is your going?\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Do you like to chat with me?\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_1\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Good morning! How are you?\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"I'm good. Just listening to some classical music. You?\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_1\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Don't know yet\"\n",
    "            }\n",
    "        }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "secont_five = \"\"\"\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"I will mention that to my the kind people in the lab,.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_1\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Just woke up\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Oh wow, I am sorry to hear that.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_1\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Why are you sprry? It is a morning here...\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"I'm not going to be late.\"\n",
    "            }\n",
    "        }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_five = \"\"\"\n",
    "       {\n",
    "            \"role\": \"participant_1\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Where are you goin?\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"To the top of the street.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_1\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"what's there?\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_2\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"Hi, I am listening to some classical music.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"participant_1\",\n",
    "            \"content\": {\n",
    "                \"emotion_scores\": {},\n",
    "                \"text\": \"you told me that already.... nevermind\"\n",
    "            }\n",
    "        },\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "foleder_name = \"intermediate\"\n",
    "\n",
    "json_file = \"/home/user1/conversation-data/dataset-01-convai/data/03_filled_data/intermediate/filled_data_intermediate_4.json\"\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "prompt\n",
      "Analyze the entire Conversation for each message and provide the emotion_scores field for the following categories: Anger, Fear, Joy, Sadness, Surprise, Love, Boredom, Neutral. The output should be in JSON format with the emotion categories as keys and their respective scores as values, totaling exactly 100. Ensure that the original format of the conversation is preserved. Although considering the context of the whole conversation, analyze each text. \n",
      "\n",
      "# Guidelines:\n",
      "1. Consider the Participant Information and Conversation Log when interpreting the emotional content of the text.\n",
      "2. Subtle emotional cues should be reflected in the corresponding emotion scores, but don't overinterpret.\n",
      "3. Assign a very high score to that emotion category when there is clear and strong evidence of a specific emotion in the text.\n",
      "\n",
      "# Participant Information: \n",
      "{'participant_1': {'name': 'Emily', 'age': 28, 'gender': 'Female', 'personality': 'Thoughtful and introspective, enjoys deep conversations and values her faith.', 'background': \"i enjoy listening to classical music. i'm a christian. my favorite color is red. i can drive a tractor. my sister is a pole dancer.\"}, 'participant_2': {'name': 'George', 'age': 35, 'gender': 'Male', 'personality': 'Pragmatic and straightforward, has a love for nature and farming.', 'background': \"i am a bee farmer. i have zero family that i'm close to. my name is george. my favorite food is papaya.\"}},\n",
      "\n",
      "# Expected output example:\n",
      "\"emotion_scores\": {\n",
      "    \"Anger\": ,\n",
      "    \"Fear\": ,\n",
      "    \"Joy\": ,\n",
      "    \"Sadness\": \n",
      "    \"Surprise\": ,\n",
      "    \"Love\": ,\n",
      "    \"Boredom\": ,\n",
      "    \"Neutral\": \n",
      "    },\n",
      "    \"text\": \"each message\",\n",
      "...\n",
      "\n",
      "# Convsersation to analyze:\n",
      "\n",
      "   \"messages\": [\n",
      "        {\n",
      "            \"role\": \"participant_2\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {},\n",
      "                \"text\": \"Hello! How is your going?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_2\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {},\n",
      "                \"text\": \"Do you like to chat with me?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_1\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {},\n",
      "                \"text\": \"Good morning! How are you?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_2\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {},\n",
      "                \"text\": \"I'm good. Just listening to some classical music. You?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_1\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {},\n",
      "                \"text\": \"Don't know yet\"\n",
      "            }\n",
      "        }\n",
      "\n",
      "\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "messages = data['messages']\n",
    "\n",
    "prompt = f\"\"\"Analyze the entire Conversation for each message and provide the emotion_scores field for the following categories: Anger, Fear, Joy, Sadness, Surprise, Love, Boredom, Neutral. The output should be in JSON format with the emotion categories as keys and their respective scores as values, totaling exactly 100. Ensure that the original format of the conversation is preserved. Although considering the context of the whole conversation, analyze each text. \n",
    "\n",
    "# Guidelines:\n",
    "1. Consider the Participant Information and Conversation Log when interpreting the emotional content of the text.\n",
    "2. Subtle emotional cues should be reflected in the corresponding emotion scores, but don't overinterpret.\n",
    "3. Assign a very high score to that emotion category when there is clear and strong evidence of a specific emotion in the text.\n",
    "\n",
    "# Participant Information: \n",
    "{data[\"participant_persona\"]},\n",
    "\n",
    "# Expected output example:\n",
    "\"emotion_scores\": {{\n",
    "    \"Anger\": ,\n",
    "    \"Fear\": ,\n",
    "    \"Joy\": ,\n",
    "    \"Sadness\": \n",
    "    \"Surprise\": ,\n",
    "    \"Love\": ,\n",
    "    \"Boredom\": ,\n",
    "    \"Neutral\": \n",
    "    }},\n",
    "    \"text\": \"each message\",\n",
    "...\n",
    "\n",
    "# Convsersation to analyze:\n",
    "{first_five}\n",
    "\"\"\"\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"prompt\")\n",
    "print(prompt)\n",
    "input_tokens = encoding.encode(prompt)\n",
    "print(\"-------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"role\": \"participant_2\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {\n",
      "                    \"Anger\": 0,\n",
      "                    \"Fear\": 0,\n",
      "                    \"Joy\": 10,\n",
      "                    \"Sadness\": 0,\n",
      "                    \"Surprise\": 0,\n",
      "                    \"Love\": 0,\n",
      "                    \"Boredom\": 0,\n",
      "                    \"Neutral\": 90\n",
      "                },\n",
      "                \"text\": \"Hello! How is your going?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_2\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {\n",
      "                    \"Anger\": 0,\n",
      "                    \"Fear\": 0,\n",
      "                    \"Joy\": 15,\n",
      "                    \"Sadness\": 0,\n",
      "                    \"Surprise\": 0,\n",
      "                    \"Love\": 0,\n",
      "                    \"Boredom\": 0,\n",
      "                    \"Neutral\": 85\n",
      "                },\n",
      "                \"text\": \"Do you like to chat with me?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_1\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {\n",
      "                    \"Anger\": 0,\n",
      "                    \"Fear\": 0,\n",
      "                    \"Joy\": 15,\n",
      "                    \"Sadness\": 0,\n",
      "                    \"Surprise\": 0,\n",
      "                    \"Love\": 0,\n",
      "                    \"Boredom\": 0,\n",
      "                    \"Neutral\": 85\n",
      "                },\n",
      "                \"text\": \"Good morning! How are you?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_2\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {\n",
      "                    \"Anger\": 0,\n",
      "                    \"Fear\": 0,\n",
      "                    \"Joy\": 20,\n",
      "                    \"Sadness\": 0,\n",
      "                    \"Surprise\": 0,\n",
      "                    \"Love\": 0,\n",
      "                    \"Boredom\": 0,\n",
      "                    \"Neutral\": 80\n",
      "                },\n",
      "                \"text\": \"I'm good. Just listening to some classical music. You?\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"participant_1\",\n",
      "            \"content\": {\n",
      "                \"emotion_scores\": {\n",
      "                    \"Anger\": 0,\n",
      "                    \"Fear\": 0,\n",
      "                    \"Joy\": 5,\n",
      "                    \"Sadness\": 5,\n",
      "                    \"Surprise\": 0,\n",
      "                    \"Love\": 0,\n",
      "                    \"Boredom\": 5,\n",
      "                    \"Neutral\": 85\n",
      "                },\n",
      "                \"text\": \"Don't know yet\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an AI assistant that helps to build conversation data set.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.8,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "\n",
    "response_content = response.choices[0].message['content']\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens = encoding.encode(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    # Ensure response_content is a string before loading as JSON\n",
    "    response_content_str = str(response_content)\n",
    "    filled_data = json.loads(response_content_str)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")\n",
    "    return  # Exit the function in case of JSONDecodeError\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"filled_data\")\n",
    "print(filled_data)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# for message in messages:\n",
    "#     content = message.get('content', {})\n",
    "#     text = content['text']\n",
    "#     if content.get('text') == text:\n",
    "#         content['emotion_scores'] = filled_data.get('emotion_scores', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total tokens\n",
    "total_tokens = len(input_tokens) + len(output_tokens)\n",
    "\n",
    "print(f\"Input Tokens: {len(input_tokens)}\")\n",
    "print(f\"Output Tokens: {len(output_tokens)}\")\n",
    "print(f\"Total Tokens: {total_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_data = label_emotion(data)\n",
    "print(f\"filled_data_export_{foleder_name}_{i + 1}:\", filled_data)\n",
    "print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'/home/user1/conversation-data/dataset-01-convai/data/04_emotion_labeled_data/{foleder_name}/test'\n",
    "output_file = os.path.join(output_dir, f'emotion_labeled_data_v2_{foleder_name}_4.json')\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(filled_data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
